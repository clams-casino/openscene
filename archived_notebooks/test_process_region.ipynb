{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ae9dfed-ec6f-4205-9431-5bbeb26a0d41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_794411/4112534512.py:9: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = cm.get_cmap('jet')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import open3d as o3d\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "cmap = cm.get_cmap('jet')\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aef85d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_space = 'openseg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41497e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_name = \"2t7WUuJeko7\"\n",
    "fused_feats_path = \"/media/rsl_admin/T7/openscene_fused_features/matterport_multiview_openseg_test/2t7WUuJeko7_region0_0.pt\"\n",
    "data_3d_path = \"/home/rsl_admin/openscene/openscene/data/matterport_3d/test/2t7WUuJeko7_region0.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff066691",
   "metadata": {},
   "source": [
    "## Setup 3D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e0e277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''simple config class to recreate what's done in the openscene code'''\n",
    "class ModelConfig:\n",
    "    def __init__(self, feature_2d_extractor, arch_3d):\n",
    "        self.feature_2d_extractor = feature_2d_extractor\n",
    "        self.arch_3d = arch_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f6f3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/home/rsl_admin/openscene/checkpoints/matterport_openseg.pth\"\n",
    "# checkpoint_path = \"/home/rsl_admin/openscene/checkpoints/scannet_openseg.pth\"\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "676dc1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run.distill import get_model\n",
    "\n",
    "model_cfg = ModelConfig(\n",
    "    feature_2d_extractor=embedding_space, \n",
    "    arch_3d='MinkUNet18A',\n",
    ")\n",
    "model = get_model(model_cfg)\n",
    "model.load_state_dict(checkpoint['state_dict'], strict=True)\n",
    "\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b32b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comparison_utils import DisNetRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db90985",
   "metadata": {},
   "outputs": [],
   "source": [
    "disnet_runner = DisNetRunner(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dca13bc",
   "metadata": {},
   "source": [
    "## Process a single region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c407ac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_regions(data_3d_path, fused_feat_path, disnet_runner):\n",
    "\n",
    "    data_fused_feat = torch.load(fused_feat_path)\n",
    "\n",
    "    data_3d = torch.load(data_3d_path)\n",
    "\n",
    "    points, colors, _ = data_3d\n",
    "\n",
    "    # Check dimensions are the same with mask full and the number of points!!!\n",
    "    assert points.shape[0] == data_fused_feat[\"mask_full\"].shape[0]\n",
    "\n",
    "    # make sure fused features are normalized\n",
    "    data_fused_feat[\"feat\"] /= (np.linalg.norm(data_fused_feat[\"feat\"], axis=1, keepdims=True) + 1e-5)\n",
    "\n",
    "    distill_feats = disnet_runner.run(points[data_fused_feat[\"mask_full\"]])\n",
    "\n",
    "    return {\n",
    "        \"points\": points[data_fused_feat[\"mask_full\"]],\n",
    "        \"colors\": colors[data_fused_feat[\"mask_full\"]],\n",
    "        \n",
    "        \"fused_feats\": data_fused_feat[\"feat\"].to(torch.float16),\n",
    "        \"distill_feats\": distill_feats.to(torch.float16),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5e54796",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_points_feats = process_regions(\n",
    "    data_3d_path,\n",
    "    fused_feats_path,\n",
    "    disnet_runner\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acd371b-67f3-4c41-850a-d40ed5d9deb9",
   "metadata": {},
   "source": [
    "## Load the scan mesh for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad043616-b963-4e1e-a742-6c52cbba78b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scan_ply_filepath = f\"/media/rsl_admin/T7/matterport/data/v1/scans/{scan_name}/{scan_name}/house_segmentations/{scan_name}.ply\"\n",
    "\n",
    "mesh_ply = o3d.io.read_triangle_mesh(scan_ply_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbf820ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(region_points_feats[\"points\"])\n",
    "pcd.colors = o3d.utility.Vector3dVector(region_points_feats[\"colors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cb5f1e1-93f8-488a-a4c6-9db3e8dddace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([mesh_ply, pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd87396",
   "metadata": {},
   "source": [
    "## Get Segmentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f30026a",
   "metadata": {},
   "source": [
    "Segment using the method done in Openscene\n",
    "\n",
    "Assume we are given a set of classes to segment out, we query all points with all class text embeddings, and take the max similarity to assign a label to the points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f0d31",
   "metadata": {},
   "source": [
    "### Set up class vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0af500dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.label_constants import MATTERPORT_LABELS_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d8738f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wall': 0, 'floor': 1, 'cabinet': 2, 'bed': 3, 'chair': 4, 'sofa': 5, 'table': 6, 'door': 7, 'window': 8, 'bookshelf': 9, 'picture': 10, 'counter': 11, 'desk': 12, 'curtain': 13, 'refrigerator': 14, 'shower curtain': 15, 'toilet': 16, 'sink': 17, 'bathtub': 18, 'other': 19, 'ceiling': 20}\n"
     ]
    }
   ],
   "source": [
    "labelset = list(MATTERPORT_LABELS_21)\n",
    "\n",
    "label_to_ind = {label: i for i, label in enumerate(labelset)}\n",
    "\n",
    "print(label_to_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f84b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.util import extract_clip_feature\n",
    "\n",
    "\n",
    "# Modified from original implementation in Openscene\n",
    "def extract_text_feature(\n",
    "    labelset, \n",
    "    prompt_eng=True,\n",
    "    feature_2d_extractor='openseg',\n",
    "    dataset='matterport_3d'\n",
    "):\n",
    "    '''extract CLIP text features.'''\n",
    "\n",
    "    # a bit of prompt engineering\n",
    "    if prompt_eng:\n",
    "        print('Use prompt engineering: a XX in a scene')\n",
    "        labelset = [ \"a \" + label + \" in a scene\" for label in labelset]\n",
    "        \n",
    "        if dataset == 'scannet_3d':\n",
    "            labelset[-1] = 'other'\n",
    "        if dataset == 'matterport_3d':\n",
    "            labelset[-2] = 'other'\n",
    "            \n",
    "    if 'lseg' in feature_2d_extractor:\n",
    "        text_features = extract_clip_feature(labelset)\n",
    "    elif 'openseg' in feature_2d_extractor:\n",
    "        text_features = extract_clip_feature(labelset, model_name=\"ViT-L/14@336px\")\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return text_features.to(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b924855d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use prompt engineering: a XX in a scene\n",
      "Loading CLIP ViT-L/14@336px model...\n",
      "Finish loading\n"
     ]
    }
   ],
   "source": [
    "label_feats = extract_text_feature(labelset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fdae085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 768])\n"
     ]
    }
   ],
   "source": [
    "print(label_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "712bd969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predictions(\n",
    "    label_feats,\n",
    "    fused_feats,\n",
    "    distill_feats,\n",
    "    method='fusion',\n",
    "):\n",
    "    assert fused_feats.shape == distill_feats.shape\n",
    "    assert fused_feats.shape[1] == label_feats.shape[1]\n",
    "    \n",
    "    # doing the matmul on gpu is way faster...\n",
    "    label_feats = label_feats.cuda()\n",
    "    fused_feats = fused_feats.cuda()\n",
    "    distill_feats = distill_feats.cuda()\n",
    "    \n",
    "    if method == 'fusion':\n",
    "        sim = fused_feats @ label_feats.T\n",
    "        pred = torch.argmax(sim, dim=1)\n",
    "        \n",
    "    elif method == 'distill':\n",
    "        sim = distill_feats @ label_feats.T\n",
    "        pred = torch.argmax(sim, dim=1)\n",
    "        \n",
    "    \n",
    "    elif method == 'ensemble':\n",
    "        sim_fusion = fused_feats @ label_feats.T\n",
    "        sim_distill = distill_feats @ label_feats.T\n",
    "        \n",
    "        max_sim_fusion, argmax_sim_fusion = torch.max(sim_fusion, dim=1)\n",
    "        max_sim_distill, argmax_sim_distill = torch.max(sim_distill, dim=1)\n",
    "        \n",
    "        pred = argmax_sim_distill\n",
    "        use_fusion = max_sim_fusion > max_sim_distill\n",
    "        pred[use_fusion] = argmax_sim_fusion[use_fusion]\n",
    "        \n",
    "    \n",
    "    return pred.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47883ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = compute_predictions(\n",
    "    label_feats,\n",
    "    region_points_feats[\"fused_feats\"],\n",
    "    region_points_feats[\"distill_feats\"],\n",
    "    method=\"ensemble\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edf60b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"desk\"\n",
    "\n",
    "label_inds = np.where(pred == label_to_ind[label])[0]\n",
    "\n",
    "o3d.visualization.draw_geometries(\n",
    "    [\n",
    "        mesh_ply, \n",
    "        pcd.select_by_index(label_inds).paint_uniform_color((0,1,0))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72a45595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     1,      3,      4, ..., 165838, 165858, 165920])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97945f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea2a676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52369aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89d8563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21b5f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def embed_string(string, encoder):\n",
    "#     with torch.no_grad():\n",
    "#         text = clip.tokenize([string]).to('cuda')\n",
    "#         text_embedding = encoder.encode_text(text)\n",
    "#         text_embedding /= text_embedding.norm(dim=-1, keepdim=True)\n",
    "#     return text_embedding.cpu().numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd958f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_similarity(\n",
    "#     query_string, \n",
    "#     fused_feat, \n",
    "#     distill_feat,\n",
    "#     method=\"fusion\"\n",
    "# ):\n",
    "#     query_embedding = embed_string(query_string, clip_pretrained)\n",
    "    \n",
    "#     if method == \"fusion\":\n",
    "#         similarity = fused_feat @ query_embedding.T\n",
    "        \n",
    "#     elif method == \"distill\":\n",
    "#         similarity = distill_feat @ query_embedding.T\n",
    "        \n",
    "#     elif method == \"ensemble\":\n",
    "#         sim_fusion = fused_feat @ query_embedding.T\n",
    "#         sim_distill = distill_feat @ query_embedding.T\n",
    "        \n",
    "#         similarity = sim_distill\n",
    "#         use_fusion = sim_fusion > sim_distill\n",
    "        \n",
    "#         print(use_fusion.shape)\n",
    "        \n",
    "#         similarity[use_fusion] = sim_fusion[use_fusion]\n",
    "#     else:\n",
    "#         raise Exception(f\"unknown method {method}\")\n",
    "    \n",
    "#     return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b8b343c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(840678, 1)\n"
     ]
    }
   ],
   "source": [
    "# scores = compute_similarity(\n",
    "#     \"a bed in a scene\", \n",
    "#     scan_points_feats[\"fused_feats\"],\n",
    "#     scan_points_feats[\"distill_feats\"],\n",
    "# #     method=\"fusion\"\n",
    "# #     method=\"distill\"\n",
    "#     method=\"ensemble\"\n",
    "# )\n",
    "\n",
    "# # under_thresh = scores < 0.2\n",
    "# # scores[under_thresh] = 0.0\n",
    "\n",
    "# query_pcd = o3d.geometry.PointCloud()\n",
    "# query_pcd.points = o3d.utility.Vector3dVector(scan_points_feats[\"points\"])\n",
    "# query_pcd.colors = o3d.utility.Vector3dVector(cmap(scores).reshape(-1,4)[:,:-1])\n",
    "# o3d.visualization.draw_geometries([query_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d201eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
